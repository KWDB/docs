#!/usr/bin/env python3
"""
Markdown å†…éƒ¨é“¾æ¥æ£€æŸ¥å™¨
æ£€æŸ¥æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ Markdown æ–‡æ¡£ä¸­çš„å†…éƒ¨é“¾æ¥æ˜¯å¦æœ‰æ•ˆ

ä½¿ç”¨æ–¹æ³•:
1. å°†æ­¤è„šæœ¬æ”¾åœ¨ docs_kaiwuDB/static ç›®å½•ä¸‹
2. ç›´æ¥è¿è¡Œ: python check_md_links.py
   (å°†è‡ªåŠ¨æ£€æŸ¥ docs_kaiwuDB ç›®å½•ä¸‹çš„æ‰€æœ‰ Markdown æ–‡ä»¶)
3. æˆ–æŒ‡å®šç›®å½•: python check_md_links.py /path/to/docs

æ³¨æ„:é»˜è®¤ä¼šæ’é™¤ staticã€node_modulesã€.git ç­‰ç›®å½•
"""

import os
import re
import sys
from pathlib import Path
from urllib.parse import unquote
from collections import defaultdict


class MarkdownLinkChecker:
    def __init__(self, root_dir, verbose=False, debug=False):
        self.root_dir = Path(root_dir).resolve()
        self.all_files = set()
        self.broken_links = defaultdict(list)
        self.total_links = 0
        self.broken_count = 0
        self.exclude_dirs = {'static', 'node_modules', '.git', '__pycache__'}  # æ’é™¤çš„ç›®å½•
        self.file_anchors_cache = {}  # ç¼“å­˜æ¯ä¸ªæ–‡ä»¶çš„é”šç‚¹åˆ—è¡¨
        self.verbose = verbose  # è¯¦ç»†æ¨¡å¼
        self.debug = debug  # è°ƒè¯•æ¨¡å¼
        self.skipped_placeholders = defaultdict(list)  # è®°å½•è¢«è·³è¿‡çš„å ä½ç¬¦
        
    def find_all_markdown_files(self):
        """æŸ¥æ‰¾æ‰€æœ‰ Markdown æ–‡ä»¶"""
        for file_path in self.root_dir.rglob("*.md"):
            if file_path.is_file():
                # æ£€æŸ¥æ–‡ä»¶è·¯å¾„ä¸­æ˜¯å¦åŒ…å«éœ€è¦æ’é™¤çš„ç›®å½•
                if not any(excluded in file_path.parts for excluded in self.exclude_dirs):
                    self.all_files.add(file_path.resolve())
        
        print(f"ğŸ“ æ‰¾åˆ° {len(self.all_files)} ä¸ª Markdown æ–‡ä»¶")
        return self.all_files
    
    def extract_anchors_from_file(self, file_path):
        """ä» Markdown æ–‡ä»¶ä¸­æå–æ‰€æœ‰å¯ç”¨çš„é”šç‚¹"""
        if file_path in self.file_anchors_cache:
            return self.file_anchors_cache[file_path]
        
        anchors = set()
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è¯»å–æ–‡ä»¶ {file_path} çš„é”šç‚¹: {e}")
            return anchors
        
        # 1. æå–æ ‡é¢˜é”šç‚¹ (# æ ‡é¢˜)
        # Markdown æ ‡é¢˜ä¼šè‡ªåŠ¨ç”Ÿæˆé”šç‚¹ï¼Œé‡å¤æ ‡é¢˜ä¼šæ·»åŠ  -1, -2, -3 ç­‰åç¼€
        # æ”¹è¿›ï¼šæ›´å®½æ¾çš„æ ‡é¢˜åŒ¹é…æ¨¡å¼ï¼Œæ”¯æŒæ ‡é¢˜ä¸­çš„å„ç§æ ¼å¼
        header_pattern = r'^(#{1,6})\s+(.+)$'
        anchor_counts = {}  # è®°å½•æ¯ä¸ªé”šç‚¹å‡ºç°çš„æ¬¡æ•°
        
        for match in re.finditer(header_pattern, content, re.MULTILINE):
            level = match.group(1)
            header_text = match.group(2).strip()
            
            # ç§»é™¤æ ‡é¢˜ä¸­çš„é“¾æ¥è¯­æ³•
            header_text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', header_text)
            # ç§»é™¤ Markdown è¯­æ³•ï¼ˆåå¼•å·ã€ç²—ä½“ã€æ–œä½“ç­‰ï¼‰
            # æ³¨æ„ï¼šä¸ç§»é™¤ä¸‹åˆ’çº¿ _ ï¼Œå› ä¸ºå®ƒå¯èƒ½æ˜¯æ ‡è¯†ç¬¦çš„ä¸€éƒ¨åˆ†
            header_text = re.sub(r'[`*~]', '', header_text)
            # ç§»é™¤ HTML æ ‡ç­¾
            header_text = re.sub(r'<[^>]+>', '', header_text)
            # ç§»é™¤å‰åç©ºæ ¼
            header_text = header_text.strip()
            
            if not header_text:
                continue
            
            # ç”Ÿæˆå¤šç§å¯èƒ½çš„é”šç‚¹æ ¼å¼
            anchor_variants = self.generate_anchor_variants(header_text)
            
            # å¯¹æ¯ç§é”šç‚¹å˜ä½“éƒ½å¤„ç†é‡å¤ç¼–å·
            for anchor in anchor_variants:
                # å¤„ç†é‡å¤é”šç‚¹
                if anchor in anchor_counts:
                    # è¿™æ˜¯é‡å¤çš„æ ‡é¢˜ï¼Œæ·»åŠ å¸¦ç¼–å·çš„ç‰ˆæœ¬
                    anchor_counts[anchor] += 1
                    numbered_anchor = f"{anchor}-{anchor_counts[anchor]}"
                    anchors.add(numbered_anchor)
                else:
                    # ç¬¬ä¸€æ¬¡å‡ºç°çš„æ ‡é¢˜
                    anchor_counts[anchor] = 0
                    anchors.add(anchor)
        
        # 2. æå– HTML é”šç‚¹ (<a name="xxx"> æˆ– <a id="xxx">)
        html_anchor_pattern = r'<a\s+(?:name|id)=["\']([^"\']+)["\']'
        for match in re.finditer(html_anchor_pattern, content, re.IGNORECASE):
            anchors.add(match.group(1))
        
        # 3. æå– HTML id å±æ€§ (<div id="xxx">)
        html_id_pattern = r'<[^>]+\s+id=["\']([^"\']+)["\']'
        for match in re.finditer(html_id_pattern, content, re.IGNORECASE):
            anchors.add(match.group(1))
        
        self.file_anchors_cache[file_path] = anchors
        return anchors
    
    def generate_anchor_variants(self, header_text):
        """
        ç”Ÿæˆé”šç‚¹ ID çš„ä¸¤ç§å˜ä½“
        1. ç§»é™¤ç‚¹å·å’Œä¸‹åˆ’çº¿ï¼ˆæ¸²æŸ“å™¨å®é™…ç”Ÿæˆçš„ï¼‰
        2. ç§»é™¤ç‚¹å·ï¼Œä¿ç•™ä¸‹åˆ’çº¿ï¼ˆæ‰‹å†™é“¾æ¥å¸¸ç”¨çš„æ ¼å¼ï¼‰
        """
        variants = set()
        
        # å˜ä½“1: ç§»é™¤ç‚¹å·å’Œä¸‹åˆ’çº¿ï¼ˆæ¸²æŸ“å™¨å®é™…è¡Œä¸ºï¼‰
        anchor1 = header_text.lower()
        anchor1 = re.sub(r'[^\w\s\u4e00-\u9fff-]', '', anchor1)  # ç§»é™¤ç‚¹å·ç­‰ï¼Œ\wåŒ…å«ä¸‹åˆ’çº¿
        anchor1 = anchor1.replace('_', '')  # ç§»é™¤ä¸‹åˆ’çº¿
        anchor1 = re.sub(r'\s+', '-', anchor1)
        anchor1 = re.sub(r'-+', '-', anchor1)
        anchor1 = anchor1.strip('-')
        if anchor1:
            variants.add(anchor1)
        
        # å˜ä½“2: ç§»é™¤ç‚¹å·ï¼Œä¿ç•™ä¸‹åˆ’çº¿ï¼ˆæ‰‹å†™é“¾æ¥æ ¼å¼ï¼‰
        anchor2 = header_text.lower()
        anchor2 = re.sub(r'[^\w\s\u4e00-\u9fff-]', '', anchor2)  # \wåŒ…å«ä¸‹åˆ’çº¿ï¼Œæ‰€ä»¥ä¸‹åˆ’çº¿è¢«ä¿ç•™
        anchor2 = re.sub(r'\s+', '-', anchor2)
        anchor2 = re.sub(r'-+', '-', anchor2)
        anchor2 = anchor2.strip('-')
        if anchor2:
            variants.add(anchor2)
        
        return variants
    
    
    def extract_links(self, content):
        """æå– Markdown ä¸­çš„æ‰€æœ‰é“¾æ¥"""
        links = []
        
        # 1. åŒ¹é… [text](link) æ ¼å¼çš„é“¾æ¥
        # æ”¹è¿›ï¼šä¸å…è®¸ text å’Œ link éƒ¨åˆ†åŒ…å«æ¢è¡Œç¬¦ï¼Œé¿å…è·¨è¡ŒåŒ¹é…è¡¨æ ¼å†…å®¹
        markdown_links = re.findall(r'\[([^\]\n]+)\]\(([^\)\n]+)\)', content)
        links.extend(markdown_links)
        
        # 2. åŒ¹é… <link> æ ¼å¼çš„é“¾æ¥(ä½†æ’é™¤ HTML æ ‡ç­¾)
        # åªåŒ¹é…çœ‹èµ·æ¥åƒ URL çš„å†…å®¹,ä¸åŒ¹é… HTML æ ‡ç­¾
        angle_bracket_pattern = r'<((?!/)(?![a-zA-Z]+\s)[^>\s]+)>'
        angle_links = re.findall(angle_bracket_pattern, content)
        # è¿‡æ»¤æ‰ http/https å¼€å¤´çš„å¤–éƒ¨é“¾æ¥
        angle_links = [(link, link) for link in angle_links 
                       if not link.startswith(('http://', 'https://', 'mailto:', 'tel:'))]
        links.extend(angle_links)
        
        return links
    
    def is_internal_link(self, link):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå†…éƒ¨é“¾æ¥"""
        # æ’é™¤å¤–éƒ¨é“¾æ¥
        if link.startswith(('http://', 'https://', 'ftp://', 'mailto:', 'tel:')):
            return False
        
        # æ’é™¤é‚®ç®±åœ°å€
        if '@' in link:
            # ç®€å•çš„é‚®ç®±æ ¼å¼æ£€æŸ¥
            if re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', link):
                return False
        
        # æ’é™¤åŸŸå (www.xxx.com æˆ– xxx.com æ ¼å¼,ä½†ä¸ä»¥ http å¼€å¤´)
        if '.' in link and not link.startswith(('./', '../')):
            # æ£€æŸ¥æ˜¯å¦ä¸ºåŸŸåæ ¼å¼(ä½†ä¸æ˜¯æ–‡ä»¶è·¯å¾„)
            if re.match(r'^(www\.)?[a-z0-9-]+(\.[a-z0-9-]+)*\.[a-z]{2,}$', link, re.IGNORECASE):
                return False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå ä½ç¬¦ - è¿™ä¸ªæ£€æŸ¥åº”è¯¥å¯¹æ‰€æœ‰éè·¯å¾„é“¾æ¥ç”Ÿæ•ˆ
        if self._is_likely_placeholder(link):
            return False
        
        return True
    
    def _is_likely_placeholder(self, link):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå ä½ç¬¦æˆ–ä»£ç å¼•ç”¨"""
        # é¦–å…ˆæ’é™¤æ˜æ˜¾çš„æ–‡ä»¶è·¯å¾„
        # ä»¥ ./ æˆ– ../ æˆ– / å¼€å¤´çš„æ˜¯æ–‡ä»¶è·¯å¾„
        if link.startswith(('./', '../', '/')):
            return False
        
        # åŒ…å«å¸¸è§æ–‡ä»¶æ‰©å±•åçš„å¯èƒ½æ˜¯çœŸå®æ–‡ä»¶(ä½†æ’é™¤ .h å¤´æ–‡ä»¶)
        common_extensions = ['.md', '.html', '.htm', '.pdf', '.doc', '.docx', 
                           '.txt', '.json', '.xml', '.yaml', '.yml', '.png', 
                           '.jpg', '.jpeg', '.gif', '.svg']
        for ext in common_extensions:
            if link.endswith(ext):
                return False
        
        # å¸¸è§çš„å ä½ç¬¦æ¨¡å¼
        placeholder_patterns = [
            # SQL/æ•°æ®åº“ç›¸å…³
            r'^[a-z_]+_name$',           # xxx_name æ ¼å¼
            r'^[a-z_]+_list$',           # xxx_list æ ¼å¼
            r'^[a-z_]+_elem$',           # xxx_elem æ ¼å¼
            r'^[a-z_]+_expr$',           # xxx_expr æ ¼å¼
            r'^[a-z]+_[a-z]+_[a-z]+$',   # xxx_xxx_xxx æ ¼å¼
            r'^[a-z]+_[a-z]+$',          # xxx_xxx æ ¼å¼(ä¸¤æ®µå¼)
            
            # ç¼–ç¨‹è¯­è¨€ç›¸å…³(Java, C#, Pythonç­‰)
            r'^[A-Z][a-zA-Z0-9]*(?:Entity|Data|Type|Class|Info|Group|Log|Version|Framework|Namespace|Using|Usings)$',  # Javaå®ä½“ç±»ç­‰
            r'^[a-z]+\.[a-z]+(?:\.[a-z]+)*$',  # å±æ€§æ ¼å¼ (å¦‚ project.build.sourceEncoding)
            r'^[a-z_]+\.[a-z_]+$',       # å¸¦ä¸‹åˆ’çº¿çš„å±æ€§æ ¼å¼ (å¦‚ meta.sql_path)
            r'^[a-z]+Id$',               # xxxId æ ¼å¼ (å¦‚ groupId, artifactId)
            r'^[A-Z][a-z]{1,5}$',        # çŸ­ç±»å (å¦‚ Row, Utc, String) - é¦–å­—æ¯å¤§å†™,åé¢1-5ä¸ªå°å†™å­—æ¯
            r'^u[0-9]+$',                # Rustç±»å‹ (å¦‚ u8, u16, u32, u64)
            r'^[A-Z][a-z]+[A-Z][a-z]+',  # é©¼å³°å‘½å (å¦‚ TargetFramework, RootNamespace)  
            
            # é€šç”¨å ä½ç¬¦
            r'^name$|^value$|^id$|^key$|^option$|^param$|^arg$',
            
            # HTML/XML æ ‡ç­¾
            r'^br/?$|^hr$|^div$|^span$',
            
            # ç‰¹æ®Šæ ¼å¼
            r'^[a-z]+\{[^}]+\}$',        # èŠ±æ‹¬å·æ ¼å¼
            r'^[a-z]+\([^)]*\)$',        # åœ†æ‹¬å·æ ¼å¼
            r'^[a-z_]+:[a-z_0-9]+$',     # å†’å·æ ¼å¼ (å¦‚ krb5_host_address:ip, ip:port)
            r'^[a-z]+-[a-z]+-[a-z]+$',   # è¿å­—ç¬¦æ ¼å¼ (å¦‚ key-path, storage-path)
            r'^[a-z]+-[a-z]+$',          # ä¸¤æ®µè¿å­—ç¬¦ (å¦‚ your-host-ip)
            
            # C/C++ å¤´æ–‡ä»¶
            r'^[a-z_]+\.h$',             # xxx.h æ ¼å¼ (å¦‚ windows.h, stdio.h)
            
            # ä»£ç /é…ç½®ç›¸å…³
            r'^base64\([^)]+\)$',        # base64(xxx) æ ¼å¼
            
            # å•å¼•å·åŒ…è£¹çš„å ä½ç¬¦
            r"^'[^']+'\s*$",             # 'xxx' æ ¼å¼
            
            # æ•°å­—ç»“å°¾çš„å˜é‡
            r'^[a-z_]+[0-9]+$',          # xxx1, xxx2 æ ¼å¼ (å¦‚ text1, int1, tag1)
            
            # è·¯å¾„å ä½ç¬¦(æ–œæ ç»“å°¾æˆ–åŒ…å«æ–œæ )
            r'^[a-zA-Z_]+/$',            # xxx/ æ ¼å¼ (å¦‚ relativePath/)
            r'^[a-z]+/[a-z]+$',          # xxx/yyy æ ¼å¼ (å¦‚ addr/host)
            
            # HTML æ³¨é‡Šæ ¼å¼
            r'^!--[^-]+-*$',             # HTML æ³¨é‡Š (å¦‚ !--Request--, !--è¯·æ±‚--)
            
            # ä¸­æ–‡å ä½ç¬¦
            r'^[\u4e00-\u9fff]+$',       # çº¯ä¸­æ–‡ (å¦‚ èšåˆå‡½æ•°, ç‰ˆæœ¬å·, æ— )
            
            # ä¸­æ–‡ç¬¦å·ç›¸å…³(æ¥è‡ªé”™è¯¯é“¾æ¥)
            r'^[`ï¼ˆï¼‰ã€=<>]+$',           # çº¯ç¬¦å·
        ]
        
        for pattern in placeholder_patterns:
            if re.match(pattern, link, re.IGNORECASE):
                return True
        
        # å¦‚æœé“¾æ¥å…¨æ˜¯å°å†™å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿,ä¸”é•¿åº¦è¾ƒçŸ­(<30å­—ç¬¦),ä¹Ÿè®¤ä¸ºæ˜¯å ä½ç¬¦
        if re.match(r'^[a-z0-9_]+$', link) and len(link) < 30:
            # ä½†æ’é™¤å¯èƒ½çš„çœŸå®æ–‡ä»¶å(å¦‚ README, index ç­‰)
            common_filenames = {'readme', 'index', 'home', 'main', 'config'}
            if link.lower() not in common_filenames:
                return True
        
        # å¦‚æœæ˜¯å…¨å¤§å†™å­—æ¯(SQL å‘½ä»¤ç­‰),ä¹Ÿè®¤ä¸ºæ˜¯å ä½ç¬¦
        if re.match(r'^[A-Z]+$', link) and len(link) > 3:
            return True
        
        # å¦‚æœåŒ…å«å¤šä¸ªä¸‹åˆ’çº¿ä¸”è¾ƒé•¿(è¶…è¿‡20å­—ç¬¦),ä¹Ÿè®¤ä¸ºæ˜¯å ä½ç¬¦
        if '_' in link and len(link) > 20:
            return True
        
        # ç‰¹æ®Šæƒ…å†µ:è¿å­—ç¬¦æ ¼å¼çš„é…ç½®é¡¹
        if '-' in link and not '/' in link:
            # å¦‚ key-path, storage-path, old-key-path ç­‰
            parts = link.split('-')
            if all(len(part) > 0 and part.islower() for part in parts):
                return True
        
        # ç‰¹æ®Šæƒ…å†µ:å†’å·åˆ†éš”çš„æ ¼å¼(å¦‚ ip:port, host:port)
        if ':' in link and not link.startswith(('http:', 'https:', 'ftp:', 'mailto:')):
            parts = link.split(':')
            if len(parts) == 2 and all(len(part) > 0 for part in parts):
                # éƒ½æ˜¯å°å†™å­—æ¯/æ•°å­—/ä¸‹åˆ’çº¿
                if all(re.match(r'^[a-z0-9_]+$', part) for part in parts):
                    return True
        
        # ç‰¹æ®Šæƒ…å†µ:åŒ…å«æ–œæ ä½†çœ‹èµ·æ¥åƒå ä½ç¬¦(å¦‚ addr/host, br/)
        # æ³¨æ„:ä»¥ / å¼€å¤´çš„å·²åœ¨æ–¹æ³•å¼€å¤´è¢«æ’é™¤
        if '/' in link:
            parts = link.split('/')
            if len(parts) == 2:
                # éƒ½æ˜¯ç®€å•çš„å°å†™å­—æ¯æˆ–ç©ºå­—ç¬¦ä¸²
                if all(re.match(r'^[a-z]*$', part) for part in parts):
                    return True
        
        # ç‰¹æ®Šæƒ…å†µ:åŒ…å«ä¸­æ–‡ç¬¦å·çš„å¼‚å¸¸é“¾æ¥(é€šå¸¸æ˜¯ Markdown æ¸²æŸ“é—®é¢˜)
        if any(char in link for char in ['`', ')', 'ã€', 'ç­‰å·', '(']):
            return True
        
        return False
    
    def check_link(self, source_file, link):
        """æ£€æŸ¥å•ä¸ªé“¾æ¥æ˜¯å¦æœ‰æ•ˆ,åŒ…æ‹¬æ–‡ä»¶å’Œé”šç‚¹"""
        # åˆ†ç¦»æ–‡ä»¶è·¯å¾„å’Œé”šç‚¹
        if '#' in link:
            link_parts = link.split('#', 1)
            link_without_anchor = link_parts[0]
            anchor = link_parts[1]
        else:
            link_without_anchor = link
            anchor = None
        
        # å¦‚æœæ˜¯çº¯é”šç‚¹é“¾æ¥(#section),æ£€æŸ¥å½“å‰æ–‡ä»¶
        if not link_without_anchor and anchor:
            target_file = source_file
        elif link_without_anchor:
            # URL è§£ç 
            link_without_anchor = unquote(link_without_anchor)
            
            # æ„å»ºç›®æ ‡æ–‡ä»¶è·¯å¾„
            if link_without_anchor.startswith('/'):
                # ç»å¯¹è·¯å¾„(ç›¸å¯¹äºæ ¹ç›®å½•)
                target_file = (self.root_dir / link_without_anchor.lstrip('/')).resolve()
            else:
                # ç›¸å¯¹è·¯å¾„(ç›¸å¯¹äºå½“å‰æ–‡ä»¶)
                target_file = (source_file.parent / link_without_anchor).resolve()
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not target_file.exists():
                return False, "æ–‡ä»¶ä¸å­˜åœ¨"
        else:
            # ç©ºé“¾æ¥
            return False, "ç©ºé“¾æ¥"
        
        # å¦‚æœæœ‰é”šç‚¹,æ£€æŸ¥é”šç‚¹æ˜¯å¦å­˜åœ¨
        if anchor:
            # URL è§£ç é”šç‚¹
            anchor = unquote(anchor)
            
            # åªæ£€æŸ¥ Markdown æ–‡ä»¶çš„é”šç‚¹
            if target_file.suffix.lower() == '.md':
                available_anchors = self.extract_anchors_from_file(target_file)
                if anchor not in available_anchors:
                    # è°ƒè¯•æ¨¡å¼ï¼šæ˜¾ç¤ºå¯ç”¨çš„é”šç‚¹
                    if self.debug:
                        print(f"\nğŸ” è°ƒè¯•ä¿¡æ¯:")
                        print(f"   ç›®æ ‡æ–‡ä»¶: {target_file.name}")
                        print(f"   æŸ¥æ‰¾é”šç‚¹: #{anchor}")
                        print(f"   å¯ç”¨é”šç‚¹ä¸­åŒ…å«å…³é”®è¯çš„:")
                        keywords = ['kwdb', 'login', 'license', 'user', 'internal']
                        for a in sorted(available_anchors):
                            if any(kw in a.lower() for kw in keywords):
                                print(f"      #{a}")
                    return False, f"é”šç‚¹ä¸å­˜åœ¨: #{anchor}"
        
        return True, None
    
    def check_file(self, file_path):
        """æ£€æŸ¥å•ä¸ª Markdown æ–‡ä»¶ä¸­çš„æ‰€æœ‰é“¾æ¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
            return
        
        links = self.extract_links(content)
        
        for text, link in links:
            # ä½¿ç”¨ is_internal_link æ¥è¿‡æ»¤,å®ƒä¼šè‡ªåŠ¨æ’é™¤å¤–éƒ¨é“¾æ¥ã€é‚®ç®±ã€åŸŸåå’Œå ä½ç¬¦
            if not self.is_internal_link(link):
                if self.verbose:
                    # è®°å½•è¢«è·³è¿‡çš„éå¤–éƒ¨é“¾æ¥(å ä½ç¬¦ç­‰)
                    if not link.startswith(('http://', 'https://', 'ftp://', 'mailto:', 'tel:')):
                        self.skipped_placeholders[file_path].append({
                            'text': text,
                            'link': link
                        })
                continue
            
            # è¿™æ˜¯çœŸå®çš„å†…éƒ¨é“¾æ¥
            self.total_links += 1
            
            is_valid, error_msg = self.check_link(file_path, link)
            if not is_valid:
                self.broken_count += 1
                self.broken_links[file_path].append({
                    'text': text,
                    'link': link,
                    'error': error_msg
                })
    
    def check_all(self):
        """æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶"""
        self.find_all_markdown_files()
        
        print(f"\nğŸ” å¼€å§‹æ£€æŸ¥å†…éƒ¨é“¾æ¥...\n")
        
        for file_path in self.all_files:
            self.check_file(file_path)
        
        self.print_report()
    
    def print_report(self):
        """æ‰“å°æ£€æŸ¥æŠ¥å‘Šå¹¶è¾“å‡ºåˆ° Markdown æ–‡ä»¶"""
        print("\n" + "="*70)
        print("ğŸ“Š æ£€æŸ¥æŠ¥å‘Š")
        print("="*70)
        
        # ç»Ÿè®¡è¢«è¿‡æ»¤çš„å ä½ç¬¦
        total_placeholders = sum(len(items) for items in self.skipped_placeholders.values())
        
        print(f"æ€»å…±æ£€æŸ¥äº† {self.total_links} ä¸ªå†…éƒ¨é“¾æ¥")
        if total_placeholders > 0:
            print(f"è·³è¿‡äº† {total_placeholders} ä¸ªå ä½ç¬¦/ä»£ç å¼•ç”¨")
        print(f"å‘ç° {self.broken_count} ä¸ªå¤±æ•ˆé“¾æ¥")
        
        # ç”Ÿæˆ Markdown æŠ¥å‘Š
        report_lines = []
        report_lines.append("# Markdown é“¾æ¥æ£€æŸ¥æŠ¥å‘Š\n")
        report_lines.append(f"**æ£€æŸ¥æ—¶é—´**: {self._get_current_time()}\n")
        report_lines.append(f"**æ£€æŸ¥ç›®å½•**: `{self.root_dir}`\n")
        report_lines.append(f"**Markdown æ–‡ä»¶æ•°**: {len(self.all_files)}\n")
        report_lines.append(f"**å†…éƒ¨é“¾æ¥æ€»æ•°**: {self.total_links}\n")
        if total_placeholders > 0:
            report_lines.append(f"**è·³è¿‡çš„å ä½ç¬¦/ä»£ç å¼•ç”¨**: {total_placeholders}\n")
        report_lines.append(f"**å¤±æ•ˆé“¾æ¥æ•°**: {self.broken_count}\n")
        report_lines.append("\n---\n\n")
        
        if self.broken_links:
            print("\nâŒ å¤±æ•ˆé“¾æ¥è¯¦æƒ…:\n")
            report_lines.append("## âŒ å¤±æ•ˆé“¾æ¥è¯¦æƒ…\n\n")
            
            for file_path, links in sorted(self.broken_links.items()):
                rel_path = file_path.relative_to(self.root_dir)
                print(f"ğŸ“„ {rel_path}")
                report_lines.append(f"### ğŸ“„ `{rel_path}`\n\n")
                
                for link_info in links:
                    print(f"   â”œâ”€ [{link_info['text']}]({link_info['link']})")
                    print(f"   â”‚  é”™è¯¯: {link_info['error']}")
                    
                    # Markdown æ ¼å¼ - ç›´æ¥æ˜¾ç¤ºåŸæ–‡
                    report_lines.append(f"- `[{link_info['text']}]({link_info['link']})`\n")
                    report_lines.append(f"  - é”™è¯¯: {link_info['error']}\n\n")
                
                print()
                report_lines.append("\n")
        else:
            print("\nâœ… æ‰€æœ‰å†…éƒ¨é“¾æ¥éƒ½æœ‰æ•ˆ!")
            report_lines.append("## âœ… æ£€æŸ¥ç»“æœ\n\n")
            report_lines.append("æ‰€æœ‰å†…éƒ¨é“¾æ¥éƒ½æœ‰æ•ˆï¼\n\n")
        
        # è¯¦ç»†æ¨¡å¼:æ˜¾ç¤ºè¢«è·³è¿‡çš„å ä½ç¬¦
        if self.verbose and self.skipped_placeholders:
            print("\n" + "="*70)
            print("â„¹ï¸  è¢«è·³è¿‡çš„å ä½ç¬¦/ä»£ç å¼•ç”¨ (è¯¦ç»†æ¨¡å¼)")
            print("="*70)
            
            report_lines.append("---\n\n")
            report_lines.append("## â„¹ï¸ è¢«è·³è¿‡çš„å ä½ç¬¦/ä»£ç å¼•ç”¨\n\n")
            report_lines.append("*ä»¥ä¸‹å†…å®¹ä»…åœ¨è¯¦ç»†æ¨¡å¼ (--verbose) ä¸‹æ˜¾ç¤º*\n\n")
            
            for file_path, placeholders in sorted(self.skipped_placeholders.items()):
                rel_path = file_path.relative_to(self.root_dir)
                print(f"\nğŸ“„ {rel_path} ({len(placeholders)} ä¸ª)")
                report_lines.append(f"### ğŸ“„ `{rel_path}` ({len(placeholders)} ä¸ª)\n\n")
                
                unique_placeholders = {}
                for p in placeholders:
                    link = p['link']
                    if link not in unique_placeholders:
                        unique_placeholders[link] = 0
                    unique_placeholders[link] += 1
                
                for link, count in sorted(unique_placeholders.items()):
                    if count > 1:
                        print(f"   â”œâ”€ [{link}]({link}) (x{count})")
                        report_lines.append(f"- `{link}` (å‡ºç° {count} æ¬¡)\n")
                    else:
                        print(f"   â”œâ”€ [{link}]({link})")
                        report_lines.append(f"- `{link}`\n")
                
                report_lines.append("\n")
            print()
        
        print("="*70)
        
        # å°†æŠ¥å‘Šå†™å…¥ Markdown æ–‡ä»¶ - ä¿å­˜åˆ° docs_kaiwuDB çš„çˆ¶ç›®å½•
        report_path = self.root_dir.parent / "link_check_report.md"
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.writelines(report_lines)
            print(f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        except Exception as e:
            print(f"\nâš ï¸  æ— æ³•ä¿å­˜æŠ¥å‘Šæ–‡ä»¶: {e}")
    
    def _get_current_time(self):
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def main():
    # æ£€æŸ¥æ˜¯å¦æœ‰ --verbose æˆ– -v å‚æ•°
    verbose = '--verbose' in sys.argv or '-v' in sys.argv
    debug = '--debug' in sys.argv or '-d' in sys.argv
    
    if verbose:
        sys.argv = [arg for arg in sys.argv if arg not in ['--verbose', '-v']]
    if debug:
        sys.argv = [arg for arg in sys.argv if arg not in ['--debug', '-d']]
    
    # å¦‚æœæ²¡æœ‰æä¾›å‚æ•°,é»˜è®¤æ£€æŸ¥è„šæœ¬æ‰€åœ¨ç›®å½•çš„ä¸Šä¸€çº§ç›®å½•(docs_kaiwuDB)
    if len(sys.argv) < 2:
        script_dir = Path(__file__).parent
        target_dir = script_dir.parent  # ä¸Šä¸€çº§ç›®å½•
        print(f"ğŸ’¡ æœªæŒ‡å®šç›®å½•,ä½¿ç”¨é»˜è®¤ç›®å½•: {target_dir}")
    else:
        target_dir = sys.argv[1]
    
    target_dir = Path(target_dir)
    
    if not target_dir.is_dir():
        print(f"âŒ é”™è¯¯: '{target_dir}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ–‡ä»¶å¤¹")
        print("\nç”¨æ³•: python check_md_links.py [æ–‡ä»¶å¤¹è·¯å¾„] [--verbose] [--debug]")
        print("ç¤ºä¾‹: python check_md_links.py ../")
        print("ç¤ºä¾‹: python check_md_links.py --verbose  # æ˜¾ç¤ºè¢«è·³è¿‡çš„å ä½ç¬¦")
        print("ç¤ºä¾‹: python check_md_links.py --debug  # æ˜¾ç¤ºé”šç‚¹è°ƒè¯•ä¿¡æ¯")
        print("å¦‚æœä¸æä¾›è·¯å¾„,å°†æ£€æŸ¥è„šæœ¬æ‰€åœ¨ç›®å½•çš„ä¸Šä¸€çº§ç›®å½•")
        sys.exit(1)
    
    if verbose:
        print("ğŸ” è¯¦ç»†æ¨¡å¼:å°†æ˜¾ç¤ºè¢«è·³è¿‡çš„å ä½ç¬¦ä¿¡æ¯")
    if debug:
        print("ğŸ› è°ƒè¯•æ¨¡å¼:å°†æ˜¾ç¤ºé”šç‚¹åŒ¹é…è¯¦æƒ…")
    
    checker = MarkdownLinkChecker(target_dir, verbose=verbose, debug=debug)
    checker.check_all()


if __name__ == "__main__":
    main()