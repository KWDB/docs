# 数据库运维

## 数据库参数配置

### 查看数据库参数

启动KaiwuDB之后可以通过show config命令查看数据库配置信息。

| 变量名              | 值                             | 描述                                                         |
| ------------------- | ------------------------------ | ------------------------------------------------------------ |
| version             | 1.9.0.2022-07-18               | 版本信息                                                     |
| auto_cluster_query  | false                          | 是否强制使用cluster select                                   |
| cluster_limit       | 100000                         | cluster select拉取数上限，0表示无上限                        |
| date_format         | %Y-%m-%d                       | 预设时间日期格式、年份                                       |
| datetime_format     | %Y-%m-%d %H:%M:%S              | 预设时间日期格式、年份                                       |
| dt32_base_year      | 2000                           | 预设时间日期基准年份                                         |
| logging             | 4                              | syslog的等级，可设定范围1-7，数字越高纪录越详细。预设为1代表没有开启，想要储存query log需设置为4，保留最多log(含OS系统 log)需设置为7 |
| max_connections     | 151                            | 同时允许的连接数。执行完即会释放连接，若超过上限新连接会等待其他连接释放 |
| max_log_files       | 30                             | query log文件数设定，详见query log说明                       |
| num_cluster_threads | 16                             | 数据库 cluster开多少执行线程                                 |
| num_threads         | 8                              | 数据库开多少执行线程                                         |
| double_precision           | 12                              | 双精度类型数据小数部分的显示位数，超出有效数字位数的数字依然会被显示，但数字不准确。小数部分最低位的0会被删除不显示|
| float_precision           | 6                            | 单精度类型数据小数部分的显示位数，超出有效数字位数的数字依然会被显示，但数字不准确。小数部分最低位的0会被删除不显示 |
| query_timeout       | 600                            | 一个query没有响应多少秒后自动停止，单位秒                    |
| stream_conn_limit   | 100                            | 数据传输连接上限，此处连接包括cluster select时数据连接、streamer汇入连接(一张表一个连接)。cluster select执行结束后连接即会断开；streamer连接则要关闭streamer才会断开。连接数由docker-compose设定 |
| zero_if_null        | true                           | 数字字段null值是否显示(存取)为0。存取时null以0存入，之后便无法更改回null |

### 修改数据库参数

可以通过以下命令进行参数修改：

```
SET <parameter_name> = <value>;
```

-  **parameter_name** ：要设置的参数名称
-  **value** ：要设置的参数值

示例：max_connections参数的设置。

```sql
> show config;
+---------------------+-------------------+
| variables_in_config | value             |
+---------------------+-------------------+
| version             | 2023-10-13        |
| version             | 2023-10-13        |
| auto_cluster_query  | false             |
| boost_level         | 1                 |
| cluster_limit       | 100000            |
| cluster_query_check | false             |
| cluster_query_retry | 2                 |
| conn_timeout        | 60                |
| date_format         | %Y-%m-%d          |
| datetime_format     | %Y-%m-%d %H:%M:%S |
| double_precision    | 12                |
| dt32_base_year      | 2000              |
| float_precision     | 6                 |
| flush_timeout       | 3000              |
| logging             | 1                 |
| max_connections     | 200               |
| max_log_files       | 30                |
| nameservice         | default           |
| ns_align            | 2                 |
| num_cluster_threads | 16                |
| num_threads         | 8                 |
| orig_order_sampling | false             |
| query_timeout       | 300               |
| spp                 | true              |
| spp_logging         | 1                 |
| ssl                 | false             |
| stream_cache_size   | 1048576           |
| stream_conn_limit   | 500               |
| table_type          | column            |
| ts_partition        | false             |
| ts_table            | true              |
| zero_if_null        | false             |
+---------------------+-------------------+
32 rows in set (0.00 sec)


> set max_connections=500;
Query OK, 0 rows affected (0.00 sec)

> show config;
+---------------------+-------------------+
| variables_in_config | value             |
+---------------------+-------------------+
| version             | 2023-10-13        |
| version             | 2023-10-13        |
| auto_cluster_query  | false             |
| boost_level         | 1                 |
| cluster_limit       | 100000            |
| cluster_query_check | false             |
| cluster_query_retry | 2                 |
| conn_timeout        | 60                |
| date_format         | %Y-%m-%d          |
| datetime_format     | %Y-%m-%d %H:%M:%S |
| double_precision    | 12                |
| dt32_base_year      | 2000              |
| float_precision     | 6                 |
| flush_timeout       | 3000              |
| logging             | 1                 |
| max_connections     | 500               |
| max_log_files       | 30                |
| nameservice         | default           |
| ns_align            | 2                 |
| num_cluster_threads | 16                |
| num_threads         | 8                 |
| orig_order_sampling | false             |
| query_timeout       | 300               |
| spp                 | true              |
| spp_logging         | 1                 |
| ssl                 | false             |
| stream_cache_size   | 1048576           |
| stream_conn_limit   | 500               |
| table_type          | column            |
| ts_partition        | false             |
| ts_table            | true              |
| zero_if_null        | false             |
+---------------------+-------------------+
32 rows in set (0.00 sec)
```

# LOG说明

KaiwuDB的log可分为系统日志和查询日志。

- 系统日志：KaiwuDB系统日志(syslog)位于：`/var/log`。当天的日志文件名为syslog；前一天为syslog.1以此类推至syslog.7.gz。每日会把syslog.7.gz删除，再将每个日志文件向后顺延，并产生新的syslog。
- 查询日志：数据库查询日志(query log)自动写入Docker内部的`:/srv/kaiwudb/ds/_log` 路径，如果启动数据库时指定了该路径映射的外部目录，则会将每笔的query log写入至该对应的docker外部文件夹内，以一个文件的形式保存。须注意不同数据库需要不同的目录来放置，以免数据混乱，互相覆盖。

log为按天生成的形式，目前默认设定一天生成一个日志文件，最多保留30天的log。

修改保留天数的方法有两种：

- 在数据库内使用命令`set max_log_files = N`; (N为数字，若N = 0不删除log)
- 在docker-compose文件内设定环境变量：MAX_LOG_FILES。
  
  示例：

```dockerfile
environment:
TZ: Asia/Shanghai
# Master: edge_node:9091
ENDPOINT: 192.168.1.121:29097
ALIAS: new
MAX_LOG_FILES: 14
```

不写入query log时设定：`set logging = 0`;

log的文件格式为名称：xx_日期.log。例如，xx_2021-09-15.log

log内容包括：写入时间、user、process id、命令类别(目前只有query)和query statement，例如，"2021-09-15 15:48:06",osadmin,68,QUERY,"select * from sample limit 10"

# 集群管理

为保证数据增长时仍可维持高效运算，KaiwuDB支持集群部署及扩展，用户可在一个KaiwuDB中执行指令，取得多个KaiwuDB的数据。发出指令的KaiwuDB为 Master，接收指令的为Client，Client端负责进行运算，运算后将结果返回到Master，Master将结果合并后把最终结果返回给用户。

## 添加节点

可以通过`add client`命令来添加client节点。

```
ADD CLIENT ip=<ip_address> db=<database_name> [port=port_number]
```

- ip_address：需要添加的client的ip地址
- database_name：需要添加的client的数据库名
- port_number：需要添加的client的端口号

示例：添加client节点。

```sql
> show cluster;
Empty set (0.00 sec)
> ADD CLIENT ip="192.168.26.101" db="ok1" port="49091";
Query OK, 0 rows affected (0.00 sec)
> ADD CLIENT ip="192.168.26.100" db="ok2" port="49091";
Query OK, 0 rows affected (0.00 sec)
> show cluster;
+----------------+----------------+-------+------+------+-------+
|      host      |       ip       |  port |  db  | type | alias |
+----------------+----------------+-------+------+------+-------+
| 192.168.26.101 | 192.168.26.101 | 49091 |  ok1 |      |       |
| 192.168.26.100 | 192.168.26.100 | 49091 |  ok2 |      |       |
+----------------+----------------+-------+------+------+-------+
2 rows in set (0.00 sec)
```

## 删除节点

可以通过`drop client`命令删除client节点。

相关命令如下：

```
DROP CLIENT ip=<ip_address> db=<database_name> [port=port_number]
```

- ip_address：需要删除的client的ip地址
- database_name：需要删除的client的数据库名
- port_number：需要删除的client的端口号

示例：删除client节点。

```sql
> show cluster;
+----------------+----------------+-------+------+------+-------+
|      host      |       ip       |  port |  db  | type | alias |
+----------------+----------------+-------+------+------+-------+
| 192.168.26.101 | 192.168.26.101 | 49091 |  ok1 |      |       |
| 192.168.26.100 | 192.168.26.100 | 49091 |  ok2 |      |       |
+----------------+----------------+-------+------+------+-------+
2 rows in set (0.00 sec)


> drop client ip="192.168.26.100" db="ok2" port="49091";
Query OK, 0 rows affected (0.00 sec)

> show cluster;
+----------------+----------------+-------+------+------+-------+
|     host       |      ip         | port  |  db  | type | alias |
+----------------+----------------+-------+------+------+-------+
| 192.168.26.101 | 192.168.26.101 | 49091 | ok1  |      |       |
+----------------+----------------+-------+------+------+-------+
1 row in set (0.00 sec)
```

## 集群查询

### 语法说明

查询表在所有节点的数据：

```sql
CLUSTER SELECT * FROM <table_name>;
```

查询表在某一个节点的数据：

```sql
CLUSTER SELECT * FROM <table_name> PARTITION BY ALIAS='<client_name>';
```

查询表在除了某个节点外的所有节点的数据：

```sql
CLUSTER SELECT * FROM <table_name> PARTITION BY ALIAS<>'<client_name>';
```

### 语法示例

示例1：相同IP不同database的集群查询。

```sql
>CREATE DATABASE log1;
Query OK, 0 rows affected (0.00 sec)

>CREATE DATABASE log2;
Query OK, 0 rows affected (0.00 sec)

>CREATE TABLE log1.log (page CHAR(64) not null default 'a', uid BIGINT not null default 0, dur INT4 not null default 0);
Query OK, 0 rows affected (0.00 sec)

>CREATE TABLE log2.log (page CHAR(64) not null default 'a', uid BIGINT not null default 0, dur INT4 not null default 0);
Query OK, 0 rows affected (0.00 sec)

>INSERT INTO log1.log VALUES ("index", 100, 30),("page1", 100, 120), ("index", 200, 50);
Query OK, 3 rows affected (0.00 sec)

>INSERT INTO log2.log VALUES ("page2", 200, 90),("index", 300, 10), ("page2", 100, 50);
Query OK, 3 rows affected (0.00 sec)

>ADD CLIENT ip="127.0.0.1" db="log1";
Query OK, 0 rows affected (0.00 sec)

>ADD CLIENT ip="127.0.0.1" db="log2";
Query OK, 0 rows affected (0.00 sec)

>SELECT * FROM log1.log;
+-------+-----+-----+
|  page |  uid|  dur|
+-------+-----+-----+
|  index|  100|  30 |
|  page1|  100| 120 |
|  index|  200|  50 |
+-------+-----+-----+
3 rows in set (0.00 sec)

>CLUSTER SELECT * FROM log;
+-------+-----+-----+
| page  | uid | dur |
+-------+-----+-----+
| index | 100 | 30  |
| page1 | 100 | 120 |
| index | 200 | 50  |
| page2 | 200 | 90  |
| index | 300 | 10  |
| page2 | 100 | 50  |
+-------+-----+-----+
6 rows in set (1 min 0.16 sec)

>SELECT page, COUNT(*) as pv from log1.log group by page;
+-------+----+
| page  | pv |
+-------+----+
| index | 2  |
| page1 | 1  | 
+-------+----+
2 rows in set (0.00 sec)

>CLUSTER SELECT page, COUNT(*) as pv from log group by page;
+-------+----+
| page  | pv |
+-------+----+
| index | 3  |
| page1 | 1  |
| page2 | 2  |
+-------+----+
3 rows in set (0.00 sec)
```

示例2：不同IP的集群查询。

```sql
> add client ip="192.168.213.129" db="log2" alias="client2";
Query OK, 0 rows affected (0.00 sec)

> add client ip="192.168.213.128" db="log1" alias="client1";
Query OK, 0 rows affected (0.00 sec)

> show cluster;
+-----------------+-----------------+-------+-------+------+---------+
|      host       |        ip       |  port |   db  | type |  alias  |
+-----------------+-----------------+-------+-------+------+---------+
|  192.168.213.129|  192.168.213.129|  9091 |  log2 |      | client2 |
|  192.168.213.128|  192.168.213.128|  9091 |  log1 |      | client1 |
+-----------------+-----------------+-------+-------+------+---------+
2 rows in set (0.00 sec)

> cluster select * from t;
+------+
| id   |
+------+
| 2    |
| 1    |
+------+
2 rows in set (0.00 sec)

> cluster select * from t partition by alias='client2';
+------+
| id   |
+------+
| 2    |
+------+
1 row in set (0.00 sec)

> cluster select * from t partition by alias<>'client2';
+------+
| id   |
+------+
| 1    |
+------+
1 row in set (0.00 sec)
```

